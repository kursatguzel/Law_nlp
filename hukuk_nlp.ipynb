{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hukuk_nlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPw4wCwNPsUy8l2v6MlKk/C"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_6Rtj2GAk5y"
      },
      "source": [
        "# Bağlantı"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QpN7bAc_MjS"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUeMI2tS_Xax",
        "outputId": "f5bfea0c-b4fd-4dcd-94c0-aad04a9277ce"
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ximFuiLv_ZWC"
      },
      "source": [
        "# Kütüphane"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnIIzUJJ_hq-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import string #noktalama işaretleri\n",
        "import re\n",
        "import nltk #etkisiz kelimeler\n",
        "import numpy\n",
        "import csv\n",
        "import pandas as pd\n",
        "import os, glob\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import requests\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orGwRTR_FT_8"
      },
      "source": [
        "# Test için örnek dava"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOVQM6WV_5qb"
      },
      "source": [
        "\n",
        "# excel'den veri yükleme\n",
        "\n",
        "from openpyxl import Workbook,load_workbook \n",
        "hukuk = pd.read_excel('/content/drive/Colab Notebooks/Hukuk/hukukk.xlsx')\n",
        "\n",
        "#ilk beş girdi görmek için\n",
        "hukuk.head() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5yAxhdKAC4f"
      },
      "source": [
        "# Veri Seti Önişleme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLxbcBaS__EP"
      },
      "source": [
        "\n",
        "nltk.download('stopwords') # önemliiiii\n",
        "noktalama = string.punctuation\n",
        "etkisiz = stopwords.words('turkish')\n",
        "print(noktalama)\n",
        "print(etkisiz)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxKTq7hlAIlX"
      },
      "source": [
        "# Eğitim Verileri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2f86kxrAJD-"
      },
      "source": [
        "dizi= []\n",
        "for d in hukuk['Karar'].head():\n",
        "\n",
        "    print(d+ '\\n------------------------------')\n",
        "    # Etkisiz kelimeleri atmak\n",
        "    temp= ' '\n",
        "    for word in d.split():\n",
        "        if word not in etkisiz and not word.isnumeric():\n",
        "            temp += word + ' '\n",
        "      \n",
        "    print(temp+ '\\n********************')\n",
        "    dizi.append(temp)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7IkUZBnAOgD"
      },
      "source": [
        "for d in hukuk['Karar'].head():\n",
        "    print(d+ '\\n------------------------------')\n",
        "    # Noktalama işaretleri atma\n",
        "    temp= ''\n",
        "    for word in d:\n",
        "        if word not in noktalama:\n",
        "            temp += word\n",
        "    print(temp+ '\\n********************')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH1j3thzARbU"
      },
      "source": [
        "# Verileri Kayıt etme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvzyV2SiAQBf"
      },
      "source": [
        "hukuk.to_csv('/content/drive/Colab Notebooks/Hukuk/cleaned.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVFYUZGSAUs4"
      },
      "source": [
        "hukuk = pd.read_csv('/content/drive/Colab Notebooks/Hukuk/cleaned.csv')\n",
        "print(hukuk.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQuob4cuAYN2"
      },
      "source": [
        "# Veri Setini Bölme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eza6LMZ0AYjL",
        "outputId": "677b696f-c6b3-4344-be34-131bb3ecc631"
      },
      "source": [
        "# Arındırılmış veriyi train ve test kümelerine ayırıyoruz\n",
        "# Eğitim ve test olarak ayıracağız. train=eğitim, test=test\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(hukuk['Karar'].values.astype('U'),hukuk['Hukum'].values.astype('U'), test_size=0.20, random_state=1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)                                                                      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(43,)\n",
            "(11,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITDrUMlIAZGg"
      },
      "source": [
        "# Sayma Vektörü Oluşturma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU_b8S30AbPh"
      },
      "source": [
        "# Train kümesindeki cümlelerin sayma vektöelerini çıkarıyoruz\n",
        "count_vect = CountVectorizer(max_features = 2000000) # Burası önemli ram için\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "print(X_train_counts.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsonRUvEAb3i"
      },
      "source": [
        "# Tf*Idf vektörü oluşturma sadece o \"karara\" özgü(temsil edecek kelimler olmalı)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg9SDKYEAdnV"
      },
      "source": [
        "# Train kümesindeki cümlelerin TF*IDF vektörlerini sayma vekttörlerinden oluşturuyoruz\n",
        "# Tf= terim sıklığı, IDF= bir kelimenin dökümanda kaç kere geçtiği\n",
        "# TF*IDF bütün olarak; bir kelimenin bir döküman içinde ki önemini gösterir\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "print(X_train_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZGHyZkTAffQ"
      },
      "source": [
        "# Naive Bayes Model Eğitimi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHyNvJ6KAfpW"
      },
      "source": [
        "# Çok modlu Naive Bayes Sınıflandırıcısı eğitiyoruz\n",
        "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
        "X_test_counts = count_vect.transform(X_test)\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CRg2MeIAgSx"
      },
      "source": [
        "# Model Performansı Ölçme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbO8dtKGAiKz"
      },
      "source": [
        "# Sınıflandırıcı ile test seti üzerindeki tahminleme yapıyoruz\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "for review, sentiment in zip(X_test[:], y_pred[:]):\n",
        "  print('%r => %s' % (review, sentiment))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCEc1eWGL3G0"
      },
      "source": [
        "# Performans sonuçları\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}